"""
Webåº”ç”¨ä¸»ç¨‹åºï¼Œæä¾›å‹å¥½çš„ç”¨æˆ·äº¤äº’ç•Œé¢
"""
import os
import sys
import logging
import streamlit as st
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
import time
import pandas as pd
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from langchain.docstore.document import Document

from document_loader import DocumentLoader
from text_splitter import get_text_splitter
from vectorizer import get_vectorizer
from retriever import get_retriever
from generator import get_generator
from evaluator import get_evaluator, RAGEvaluator
from data_converter import DocumentConverter, StructuredOutput
from utils.helpers import time_function, ensure_directory, format_source_documents
from config.config import (
    DATA_DIR, VECTOR_STORE_DIR, EVAL_DATA_DIR, EVAL_RESULTS_DIR,
    CHUNK_SIZE, CHUNK_OVERLAP, EMBEDDING_MODEL, TOP_K, 
    OPENAI_API_KEY, OPENAI_MODEL, DEEPSEEK_API_KEY, DEEPSEEK_MODEL,
    DEFAULT_LLM_PROVIDER, LLM_TEMPERATURE, LLM_MAX_TOKENS,
    DEFAULT_EVAL_DATASET,
    APP_TITLE, APP_DESCRIPTION,
    USE_HYBRID, USE_RERANKER,
    VECTOR_WEIGHT, BM25_WEIGHT
)
from models.deepseek_llm import DeepSeekLLM

# å°†æ„å›¾è¯†åˆ«é»˜è®¤è®¾ç½®ä¸ºFalse
USE_INTENT_RECOGNITION = False
INTENT_MODEL = "bert-base-chinese"

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(
    page_title=APP_TITLE,
    page_icon="ğŸ”",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title(APP_TITLE)
st.markdown(APP_DESCRIPTION)

# ä¾§è¾¹æ é…ç½®
st.sidebar.title("é…ç½®")

# ç¡®ä¿ç›®å½•å­˜åœ¨
ensure_directory(DATA_DIR)
ensure_directory(VECTOR_STORE_DIR)
ensure_directory(EVAL_DATA_DIR)
ensure_directory(EVAL_RESULTS_DIR)

# åŠŸèƒ½é€‰æ‹©
app_mode = st.sidebar.selectbox(
    "é€‰æ‹©åŠŸèƒ½",
    ["RAGé—®ç­”ç³»ç»Ÿ", "æ–‡æ¡£ç»“æ„åŒ–è½¬æ¢"],
    index=0
)

# æ¨¡å‹æä¾›å•†é€‰æ‹©
model_provider = st.sidebar.selectbox(
    "é€‰æ‹©æ¨¡å‹æä¾›å•†",
    options=["OpenAI", "DeepSeek"],
    index=0 if DEFAULT_LLM_PROVIDER == "openai" else 1
)

# API Keyè¾“å…¥
if model_provider == "OpenAI":
    api_key = st.sidebar.text_input(
        "OpenAI API Key", 
        value=os.getenv("OPENAI_API_KEY", ""),
        type="password"
    )
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
        
    # æ¨¡å‹é€‰æ‹©
    model_name = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        options=["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"],
        index=0
    )
else:  # DeepSeek
    api_key = st.sidebar.text_input(
        "DeepSeek API Key", 
        value=os.getenv("DEEPSEEK_API_KEY", ""),
        type="password"
    )
    if api_key:
        os.environ["DEEPSEEK_API_KEY"] = api_key
        
    # æ¨¡å‹é€‰æ‹©
    model_name = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        options=["deepseek-chat", "deepseek-coder"],
        index=0
    )

# æ¸©åº¦å‚æ•°
temperature = st.sidebar.slider(
    "ç”Ÿæˆæ¸©åº¦",
    min_value=0.0,
    max_value=1.0,
    value=LLM_TEMPERATURE,
    step=0.1,
    help="è¾ƒä½çš„å€¼ä½¿è¾“å‡ºæ›´ç¡®å®šï¼Œè¾ƒé«˜çš„å€¼ä½¿è¾“å‡ºæ›´éšæœº"
)

# æœ€å¤§ç”Ÿæˆé•¿åº¦
max_tokens = st.sidebar.slider(
    "æœ€å¤§ç”Ÿæˆé•¿åº¦",
    min_value=256,
    max_value=4096,
    value=LLM_MAX_TOKENS,
    step=256,
    help="é™åˆ¶ç”Ÿæˆå›ç­”çš„æœ€å¤§tokenæ•°é‡"
)

# RAGé—®ç­”ç³»ç»Ÿæ¨¡å¼
if app_mode == "RAGé—®ç­”ç³»ç»Ÿ":
    # æ£€ç´¢æ•°é‡
    top_k = st.sidebar.slider(
        "æ£€ç´¢ç»“æœæ•°é‡",
        min_value=1,
        max_value=10,
        value=TOP_K,
        step=1,
        help="æ£€ç´¢çš„æ–‡æ¡£ç‰‡æ®µæ•°é‡"
    )

    # æ˜¯å¦ä½¿ç”¨è®°å¿†
    use_memory = st.sidebar.checkbox(
        "å¯ç”¨å¯¹è¯è®°å¿†",
        value=True,
        help="è®°ä½å¯¹è¯å†å²ä»¥æä¾›æ›´è¿è´¯çš„å›ç­”"
    )

    # æ˜¯å¦ä½¿ç”¨æ„å›¾è¯†åˆ«
    use_intent_recognition = st.sidebar.checkbox(
        "å¯ç”¨æ„å›¾è¯†åˆ«",
        value=USE_INTENT_RECOGNITION,
        help="è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·é—®é¢˜æ„å›¾ï¼Œä¼˜åŒ–æ£€ç´¢å’Œç”Ÿæˆç­–ç•¥"
    )

    # é«˜çº§æ£€ç´¢è®¾ç½®
    with st.sidebar.expander("é«˜çº§æ£€ç´¢è®¾ç½®", expanded=False):
        use_hybrid = st.checkbox(
            "å¯ç”¨æ··åˆæ£€ç´¢",
            value=USE_HYBRID,
            help="ç»“åˆå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢"
        )
        
        use_reranker = st.checkbox(
            "å¯ç”¨é‡æ’åº",
            value=USE_RERANKER,
            help="ä½¿ç”¨Cross-Encoderå¯¹æ£€ç´¢ç»“æœé‡æ’åº"
        )
        
        vector_weight = st.slider(
            "å‘é‡æ£€ç´¢æƒé‡",
            min_value=0.0,
            max_value=1.0,
            value=VECTOR_WEIGHT,
            step=0.1,
            help="æ··åˆæ£€ç´¢ä¸­å‘é‡æ£€ç´¢çš„æƒé‡"
        )
        
        bm25_weight = st.slider(
            "BM25æ£€ç´¢æƒé‡",
            min_value=0.0,
            max_value=1.0,
            value=BM25_WEIGHT,
            step=0.1,
            help="æ··åˆæ£€ç´¢ä¸­BM25æ£€ç´¢çš„æƒé‡"
        )

    # å‘é‡å­˜å‚¨ç±»å‹
    vector_store_type = st.sidebar.selectbox(
        "å‘é‡å­˜å‚¨ç±»å‹",
        options=["FAISS", "Chroma"],
        index=0
    )

    # æ„å›¾è¯†åˆ«è®¾ç½®
    with st.sidebar.expander("æ„å›¾è¯†åˆ«è®¾ç½®", expanded=False):
        if use_intent_recognition:
            intent_model = st.selectbox(
                "æ„å›¾è¯†åˆ«æ¨¡å‹",
                options=["bert-base-chinese", "roberta-base-chinese"],
                index=0,
                help="ç”¨äºè¯†åˆ«ç”¨æˆ·æ„å›¾çš„é¢„è®­ç»ƒæ¨¡å‹"
            )
            
    # è®¾ç½®ä¼šè¯çŠ¶æ€
    if "messages" not in st.session_state:
        st.session_state.messages = []
        
    if "retriever" not in st.session_state:
        st.session_state.retriever = None
        
    if "generator" not in st.session_state:
        st.session_state.generator = None
        
    if "intent_recognizer" not in st.session_state:
        st.session_state.intent_recognizer = None

    # é€‰é¡¹å¡ï¼šèŠå¤©ã€çŸ¥è¯†åº“ç®¡ç†ã€è¯„ä¼°
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ èŠå¤©", "ğŸ“š çŸ¥è¯†åº“ç®¡ç†", "ğŸ“Š ç³»ç»Ÿè¯„ä¼°"])

    # èŠå¤©é€‰é¡¹å¡
    with tab1:
        # æ˜¾ç¤ºèŠå¤©å†å²
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                if message.get("source_documents"):
                    with st.expander("æŸ¥çœ‹å¼•ç”¨æ¥æº"):
                        st.markdown(format_source_documents(message["source_documents"]))
        
        # åˆ›å»ºæ£€ç´¢å™¨ï¼ˆå¦‚æœå°šæœªåˆ›å»ºï¼‰
        if not st.session_state.retriever:
            try:
                # åˆå§‹åŒ–å‘é‡åŒ–å™¨
                vectorizer = get_vectorizer(
                    embedding_model_name=EMBEDDING_MODEL,
                    vector_store_dir=VECTOR_STORE_DIR,
                    vector_store_type=vector_store_type.lower()
                )
                
                # åŠ è½½å‘é‡å­˜å‚¨
                vector_store = vectorizer.load_vector_store()
                
                # åˆå§‹åŒ–æ£€ç´¢å™¨
                st.session_state.retriever = get_retriever(
                    vector_store=vector_store,
                    top_k=top_k,
                    use_hybrid=use_hybrid,
                    use_reranker=use_reranker,
                    vector_weight=vector_weight,
                    bm25_weight=bm25_weight
                )
            except Exception as e:
                st.error(f"åˆå§‹åŒ–æ£€ç´¢å™¨å¤±è´¥: {str(e)}")
                st.warning("è¯·ç¡®ä¿å·²ä¸Šä¼ å¹¶å¤„ç†äº†çŸ¥è¯†åº“æ–‡æ¡£ï¼Œæˆ–æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®ã€‚")
                
        # åˆ›å»ºç”Ÿæˆå™¨ï¼ˆå¦‚æœå°šæœªåˆ›å»ºï¼‰
        if not st.session_state.generator:
            try:
                st.session_state.generator = get_generator(
                    retriever=st.session_state.retriever,
                    model_name=model_name,
                    api_key=api_key,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    use_memory=use_memory,
                    provider=model_provider.lower()
                )
            except Exception as e:
                st.error(f"åˆå§‹åŒ–ç”Ÿæˆå™¨å¤±è´¥: {str(e)}")
                st.warning("è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®ã€‚")
                
        # åˆ›å»ºæ„å›¾è¯†åˆ«å™¨ï¼ˆå¦‚æœå¯ç”¨ä¸”å°šæœªåˆ›å»ºï¼‰
        if use_intent_recognition and not st.session_state.intent_recognizer:
            try:
                from intent_recognizer import IntentRecognizer
                st.session_state.intent_recognizer = IntentRecognizer(
                    model_name=intent_model or INTENT_MODEL
                )
            except Exception as e:
                st.error(f"åˆå§‹åŒ–æ„å›¾è¯†åˆ«å™¨å¤±è´¥: {str(e)}")
                st.warning("è¯·æ£€æŸ¥æ¨¡å‹é…ç½®æ˜¯å¦æ­£ç¡®ã€‚")
                use_intent_recognition = False
        
        # ç”¨æˆ·è¾“å…¥
        if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜"):
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯ï¼ˆå¸¦åŠ è½½åŠ¨ç”»ï¼‰
            with st.chat_message("assistant"):
                if st.session_state.retriever and st.session_state.generator:
                    try:
                        message_placeholder = st.empty()
                        
                        # è¯†åˆ«æ„å›¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        intent_type = None
                        if use_intent_recognition and st.session_state.intent_recognizer:
                            with st.spinner("æ­£åœ¨åˆ†æé—®é¢˜æ„å›¾..."):
                                intent_type = st.session_state.intent_recognizer.predict_intent(prompt)
                                st.session_state.messages[-1]["intent"] = intent_type
                                
                        # æ‰§è¡Œæ£€ç´¢
                        with st.spinner("æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£..."):
                            search_results = st.session_state.retriever.search(
                                query=prompt,
                                top_k=top_k,
                                intent_type=intent_type
                            )
                            
                        # ç”Ÿæˆå›ç­”
                        with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                            response = st.session_state.generator.generate_answer(
                                query=prompt,
                                search_results=search_results,
                                intent_type=intent_type
                            )
                            
                        # æ˜¾ç¤ºå›ç­”
                        message_placeholder.markdown(response.answer)
                        
                        # æ˜¾ç¤ºå¼•ç”¨æ¥æº
                        if response.source_documents:
                            with st.expander("æŸ¥çœ‹å¼•ç”¨æ¥æº"):
                                st.markdown(format_source_documents(response.source_documents))
                                
                        # æ·»åŠ å›ç­”åˆ°å†å²
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": response.answer,
                            "source_documents": response.source_documents
                        })
            
                    except Exception as e:
                        err_msg = f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
                        st.error(err_msg)
                        st.session_state.messages.append({"role": "assistant", "content": err_msg})
                else:
                    err_msg = "ç³»ç»Ÿæœªå‡†å¤‡å°±ç»ªï¼Œè¯·æ£€æŸ¥é…ç½®å¹¶ç¡®ä¿å·²åŠ è½½çŸ¥è¯†åº“"
                    st.error(err_msg)
                    st.session_state.messages.append({"role": "assistant", "content": err_msg})

    # çŸ¥è¯†åº“ç®¡ç†é€‰é¡¹å¡
    with tab2:
        st.header("çŸ¥è¯†åº“ç®¡ç†")
        
        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“", 
            type=["pdf", "docx", "doc", "txt", "csv"],
            accept_multiple_files=True
        )
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            chunk_size_upload = st.number_input(
                "æ–‡æœ¬å—å¤§å°",
                min_value=100,
                max_value=2000,
                value=CHUNK_SIZE,
                step=50
            )
            
        with col2:
            chunk_overlap_upload = st.number_input(
                "å—é‡å å¤§å°",
                min_value=0,
                max_value=500,
                value=CHUNK_OVERLAP,
                step=10
            )
            
        with col3:
            embedding_model_upload = st.selectbox(
                "å‘é‡æ¨¡å‹",
                options=["BAAI/bge-large-zh", "BAAI/bge-small-zh", "text2vec-large-chinese"],
                index=0
            )
        
        # å¤„ç†ä¸Šä¼ æ–‡ä»¶
        if uploaded_files and st.button("å¤„ç†å¹¶ç´¢å¼•æ–‡æ¡£"):
            with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                # ä¿å­˜ä¸Šä¼ æ–‡ä»¶
                saved_files = []
                for uploaded_file in uploaded_files:
                    file_path = os.path.join(DATA_DIR, uploaded_file.name)
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                        saved_files.append(file_path)
                
                st.success(f"å·²ä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶åˆ°æ•°æ®ç›®å½•")
                
                # åŠ è½½å’Œå¤„ç†æ–‡æ¡£
                try:
                    # åˆå§‹åŒ–æ–‡æ¡£åŠ è½½å™¨
                    loader = DocumentLoader(DATA_DIR)
                
                    # åŠ è½½æ–‡æ¡£
                    documents = loader.load_documents(saved_files)
                    st.info(f"å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
                
                    # æ–‡æœ¬åˆ†å—
                    text_splitter = get_text_splitter(
                        splitter_type="recursive",
                        chunk_size=chunk_size_upload,
                        chunk_overlap=chunk_overlap_upload
                    )
                    chunks = text_splitter.split_documents(documents)
                    st.info(f"å·²åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")
                
                    # åˆå§‹åŒ–å‘é‡åŒ–å™¨
                    vectorizer = get_vectorizer(
                        embedding_model_name=embedding_model_upload,
                        vector_store_dir=VECTOR_STORE_DIR,
                        vector_store_type=vector_store_type.lower()
                    )
                
                    # åˆ›å»ºæˆ–æ›´æ–°å‘é‡å­˜å‚¨
                    vector_store = vectorizer.load_vector_store()
                    if vector_store is not None:
                        # æ·»åŠ åˆ°ç°æœ‰å‘é‡å­˜å‚¨
                        vector_store = vectorizer.add_documents(chunks, vector_store)
                    else:
                        # åˆ›å»ºæ–°çš„å‘é‡å­˜å‚¨
                        vector_store = vectorizer.create_vector_store(chunks)
                    
                    # æ›´æ–°æ£€ç´¢å™¨
                    if st.session_state.retriever is not None:
                        st.session_state.retriever.update_vector_store(vector_store)
                    else:
                        # åˆ›å»ºæ–°çš„æ£€ç´¢å™¨
                        st.session_state.retriever = get_retriever(
                            vector_store=vector_store,
                            top_k=top_k,
                            use_hybrid=use_hybrid,
                            use_reranker=use_reranker,
                            vector_weight=vector_weight,
                            bm25_weight=bm25_weight
                        )
                    
                    st.success(f"æˆåŠŸå¤„ç†å¹¶ç´¢å¼• {len(chunks)} ä¸ªæ–‡æœ¬å—")
                
                except Exception as e:
                    st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
        
        # çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯
        st.subheader("çŸ¥è¯†åº“ç»Ÿè®¡")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if os.path.exists(DATA_DIR):
                data_files = [f for f in os.listdir(DATA_DIR) if os.path.isfile(os.path.join(DATA_DIR, f))]
                st.metric("æ•°æ®æ–‡ä»¶æ•°é‡", len(data_files))
            else:
                st.metric("æ•°æ®æ–‡ä»¶æ•°é‡", 0)
        
        with col2:
            if st.session_state.retriever:
                try:
                    doc_count = st.session_state.retriever.get_document_count()
                    st.metric("ç´¢å¼•æ–‡æ¡£æ•°é‡", doc_count)
                except:
                    st.metric("ç´¢å¼•æ–‡æ¡£æ•°é‡", "æœªçŸ¥")
            else:
                st.metric("ç´¢å¼•æ–‡æ¡£æ•°é‡", 0)
            
        # æ˜¾ç¤ºæ•°æ®ç›®å½•æ–‡ä»¶åˆ—è¡¨
        if os.path.exists(DATA_DIR):
            with st.expander("æŸ¥çœ‹æ•°æ®æ–‡ä»¶"):
                data_files = [f for f in os.listdir(DATA_DIR) if os.path.isfile(os.path.join(DATA_DIR, f))]
                for file in data_files:
                    st.text(file)

    # è¯„ä¼°é€‰é¡¹å¡
    with tab3:
        st.header("ç³»ç»Ÿè¯„ä¼°")
        
        # åŠ è½½è¯„ä¼°æ•°æ®é›†
        eval_datasets = [f for f in os.listdir(EVAL_DATA_DIR) if f.endswith('.json')]
        
        if not eval_datasets:
            st.warning("æœªæ‰¾åˆ°è¯„ä¼°æ•°æ®é›†ï¼Œè¯·ä¸Šä¼ è‡³è¯„ä¼°æ•°æ®ç›®å½•")
        else:
            selected_dataset = st.selectbox(
                "é€‰æ‹©è¯„ä¼°æ•°æ®é›†",
                options=eval_datasets,
                index=0
            )
        
            # è¯„ä¼°é…ç½®
            col1, col2 = st.columns(2)
            
            with col1:
                eval_retriever = st.checkbox("è¯„ä¼°æ£€ç´¢è´¨é‡", value=True)
                eval_generation = st.checkbox("è¯„ä¼°ç”Ÿæˆè´¨é‡", value=True)
                
            with col2:
                num_samples = st.number_input(
                    "è¯„ä¼°æ ·æœ¬æ•°é‡",
                    min_value=1,
                    max_value=100,
                    value=5,
                    step=1,
                    help="é™åˆ¶è¯„ä¼°çš„é—®é¢˜æ•°é‡"
                )
            
            # æ‰§è¡Œè¯„ä¼°
            if st.button("å¼€å§‹è¯„ä¼°"):
                if not st.session_state.retriever or not st.session_state.generator:
                    st.error("è¯·å…ˆç¡®ä¿æ£€ç´¢å™¨å’Œç”Ÿæˆå™¨å·²åˆå§‹åŒ–")
                else:
                    try:
                        with st.spinner("æ­£åœ¨è¿›è¡Œè¯„ä¼°..."):
                            # åˆå§‹åŒ–è¯„ä¼°å™¨
                            evaluator = get_evaluator(
                                provider=model_provider.lower(),
                                model_name=model_name
                            )
                            
                            # åŠ è½½æ•°æ®é›†
                            dataset_path = os.path.join(EVAL_DATA_DIR, selected_dataset)
                            
                            # æ‰§è¡Œè¯„ä¼°
                            eval_results = evaluator.evaluate(
                                dataset_path=dataset_path,
                                retriever=st.session_state.retriever,
                                generator=st.session_state.generator,
                                eval_retrieval=eval_retriever,
                                eval_generation=eval_generation,
                                num_samples=num_samples
                            )
                            
                            # ç”Ÿæˆå”¯ä¸€çš„ç»“æœæ–‡ä»¶å
                            timestamp = int(time.time())
                            result_file = f"eval_result_{timestamp}.json"
                            result_path = os.path.join(EVAL_RESULTS_DIR, result_file)
                            
                            # ä¿å­˜ç»“æœ
                            with open(result_path, 'w', encoding='utf-8') as f:
                                json.dump(eval_results, f, ensure_ascii=False, indent=2)
                                
                            st.success(f"è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³: {result_file}")
                            
                            # æ˜¾ç¤ºç»“æœæ‘˜è¦
                            if eval_retriever and "retrieval" in eval_results:
                                st.subheader("æ£€ç´¢è¯„ä¼°ç»“æœ")
                                retrieval_metrics = eval_results["retrieval"]["metrics"]
                                
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    st.metric("ç²¾ç¡®ç‡ (Precision)", f"{retrieval_metrics.get('precision', 0):.3f}")
                                    
                                with col2:
                                    st.metric("å¬å›ç‡ (Recall)", f"{retrieval_metrics.get('recall', 0):.3f}")
                                    
                                with col3:
                                    st.metric("F1åˆ†æ•°", f"{retrieval_metrics.get('f1', 0):.3f}")
                                    
                            if eval_generation and "generation" in eval_results:
                                st.subheader("ç”Ÿæˆè¯„ä¼°ç»“æœ")
                                generation_metrics = eval_results["generation"]["metrics"]
                                
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.metric("ç›¸å…³æ€§å¾—åˆ†", f"{generation_metrics.get('relevance', 0):.3f}")
                                    
                                with col2:
                                    st.metric("å¿ å®åº¦å¾—åˆ†", f"{generation_metrics.get('faithfulness', 0):.3f}")
                                    
                            # è¯¦ç»†ç»“æœæŸ¥çœ‹
                            with st.expander("æŸ¥çœ‹è¯¦ç»†è¯„ä¼°ç»“æœ"):
                                st.json(eval_results)
                                
                    except Exception as e:
                        st.error(f"è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                        
        # æŸ¥çœ‹å†å²è¯„ä¼°ç»“æœ
        st.subheader("å†å²è¯„ä¼°ç»“æœ")
        
        if os.path.exists(EVAL_RESULTS_DIR):
            result_files = [f for f in os.listdir(EVAL_RESULTS_DIR) if f.endswith('.json')]
            
            if not result_files:
                st.info("æš‚æ— å†å²è¯„ä¼°ç»“æœ")
            else:
                selected_result = st.selectbox(
                    "é€‰æ‹©æŸ¥çœ‹ç»“æœ",
                    options=result_files,
                    index=0
                )
                
                if selected_result:
                    result_path = os.path.join(EVAL_RESULTS_DIR, selected_result)
                    
                    try:
                        with open(result_path, 'r', encoding='utf-8') as f:
                            result_data = json.load(f)
                        
                        with st.expander("æŸ¥çœ‹ç»“æœè¯¦æƒ…"):
                            st.json(result_data)
                            
                    except Exception as e:
                        st.error(f"åŠ è½½ç»“æœæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        else:
            st.info("è¯„ä¼°ç»“æœç›®å½•ä¸å­˜åœ¨")

# æ–‡æ¡£ç»“æ„åŒ–è½¬æ¢æ¨¡å¼
elif app_mode == "æ–‡æ¡£ç»“æ„åŒ–è½¬æ¢":
    st.header("æ–‡æ¡£ç»“æ„åŒ–è½¬æ¢")
    st.markdown("å°†å¤šç§æ ¼å¼çš„æ–‡æ¡£è½¬æ¢ä¸ºAIå‹å¥½çš„ç»“æ„åŒ–æ•°æ®æ ¼å¼ï¼ŒåŒ…æ‹¬JSONã€é—®ç­”å¯¹ç­‰")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ æ–‡æ¡£",
        type=["pdf", "docx", "doc", "txt", "xlsx", "xls", "csv"],
        help="æ”¯æŒPDFã€Wordã€Excelå’Œçº¯æ–‡æœ¬æ–‡ä»¶"
    )
    
    # è½¬æ¢é€‰é¡¹
    with st.expander("è½¬æ¢é€‰é¡¹", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            output_formats = st.multiselect(
                "é€‰æ‹©è¾“å‡ºæ ¼å¼",
                options=["JSON", "JSONL", "é—®ç­”å¯¹", "æ–‡æœ¬å—"],
                default=["JSON", "é—®ç­”å¯¹"]
            )
            
            use_ocr = st.checkbox(
                "ä½¿ç”¨OCRå¤„ç†æ‰«ææ–‡æ¡£",
                value=True,
                help="å¯¹PDFç­‰æ–‡æ¡£ä½¿ç”¨å…‰å­¦å­—ç¬¦è¯†åˆ«æŠ€æœ¯æå–æ–‡æœ¬"
            )
        
        with col2:
            chunk_size = st.slider(
                "æ–‡æœ¬å—å¤§å°",
                min_value=100,
                max_value=2000,
                value=CHUNK_SIZE,
                step=50
            )
            
            chunk_overlap = st.slider(
                "å—é‡å å¤§å°",
                min_value=0,
                max_value=500,
                value=CHUNK_OVERLAP,
                step=10
            )
            
            qa_per_chunk = st.slider(
                "æ¯å—é—®ç­”å¯¹æ•°é‡",
                min_value=1,
                max_value=5,
                value=3,
                step=1,
                help="ä¸ºæ¯ä¸ªæ–‡æœ¬å—ç”Ÿæˆçš„é—®ç­”å¯¹æ•°é‡"
            )
    
    # å¤„ç†æŒ‰é’®
    if uploaded_file and st.button("å¼€å§‹å¤„ç†"):
        with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            temp_file_path = os.path.join(DATA_DIR, uploaded_file.name)
            with open(temp_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # åˆå§‹åŒ–è½¬æ¢å™¨
            converter = DocumentConverter(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                llm_provider=model_provider.lower(),
                temperature=temperature,
                use_ocr=use_ocr,
                api_key=api_key
            )
            
            # å¤„ç†æ–‡æ¡£
            try:
                result = converter.process_document(
                    temp_file_path,
                    output_formats=[f.lower() for f in output_formats]
                )
                
                # æ˜¾ç¤ºç»“æœ
                st.success(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼å…±ç”Ÿæˆ {len(result.text_chunks)} ä¸ªæ–‡æœ¬å—ã€‚")
                
                # æ˜¾ç¤ºæ–‡æœ¬å—
                if "æ–‡æœ¬å—" in output_formats:
                    with st.expander("æ–‡æœ¬å—é¢„è§ˆ", expanded=False):
                        for i, chunk in enumerate(result.text_chunks[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                            st.markdown(f"**å— {i+1}**")
                            st.text(chunk["content"][:500] + "..." if len(chunk["content"]) > 500 else chunk["content"])
                            st.json(chunk["metadata"])
                        if len(result.text_chunks) > 5:
                            st.info(f"è¿˜æœ‰ {len(result.text_chunks) - 5} ä¸ªæ–‡æœ¬å—æœªæ˜¾ç¤º")
            
                # æ˜¾ç¤ºé—®ç­”å¯¹
                if "é—®ç­”å¯¹" in output_formats and result.qa_pairs:
                    with st.expander("é—®ç­”å¯¹é¢„è§ˆ", expanded=True):
                        for i, qa in enumerate(result.qa_pairs[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
                            st.markdown(f"**é—®é¢˜ {i+1}**: {qa.question}")
                            st.markdown(f"**å›ç­”**: {qa.answer}")
                            st.markdown("---")
                
                # æ˜¾ç¤ºè¡¨æ ¼æ•°æ®
                if result.tables:
                    with st.expander("è¡¨æ ¼æ•°æ®é¢„è§ˆ", expanded=True):
                        for i, table in enumerate(result.tables[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªè¡¨æ ¼
                            st.markdown(f"**è¡¨æ ¼ {i+1}** (æ¥è‡ª: {table.get('sheet_name', 'æœªçŸ¥å·¥ä½œè¡¨')})")
                            
                            if 'data' in table and table['data']:
                                df = pd.DataFrame(table['data'])
                                st.dataframe(df)
                            else:
                                st.info("è¡¨æ ¼æ— æ•°æ®æˆ–æ•°æ®ä¸ºç©º")
                            
                            st.markdown("---")
                
                # æä¾›ä¸‹è½½
                st.subheader("ä¸‹è½½è½¬æ¢ç»“æœ")
                
                # JSONä¸‹è½½
                if "JSON" in output_formats:
                    json_str = result.model_dump_json(indent=2)
                    st.download_button(
                        label="ä¸‹è½½å®Œæ•´JSONæ–‡ä»¶",
                        data=json_str.encode("utf-8"),
                        file_name=f"{os.path.splitext(uploaded_file.name)[0]}_structured.json",
                        mime="application/json"
                    )
                
                # JSONLä¸‹è½½
                if "JSONL" in output_formats:
                    jsonl_str = converter.convert_to_format(result, "jsonl")
                    st.download_button(
                        label="ä¸‹è½½JSONLæ–‡ä»¶",
                        data=jsonl_str.encode("utf-8"),
                        file_name=f"{os.path.splitext(uploaded_file.name)[0]}_chunks.jsonl",
                        mime="application/jsonl"
                    )
                
                # é—®ç­”å¯¹ä¸‹è½½
                if "é—®ç­”å¯¹" in output_formats and result.qa_pairs:
                    qa_json = converter.convert_to_format(result, "qa_json")
                    st.download_button(
                        label="ä¸‹è½½é—®ç­”å¯¹JSONæ–‡ä»¶",
                        data=qa_json.encode("utf-8"),
                        file_name=f"{os.path.splitext(uploaded_file.name)[0]}_qa_pairs.json",
                        mime="application/json"
                    )
                    
            except Exception as e:
                st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                logging.error(f"å¤„ç†æ–‡æ¡£å¤±è´¥: {temp_file_path}, é”™è¯¯: {str(e)}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            # os.remove(temp_file_path)
    
    # è¯´æ˜å’Œç¤ºä¾‹
    with st.expander("åŠŸèƒ½è¯´æ˜å’Œä½¿ç”¨ç¤ºä¾‹", expanded=False):
        st.markdown("""
        ### æ–‡æ¡£ç»“æ„åŒ–è½¬æ¢åŠŸèƒ½è¯´æ˜

        æ­¤åŠŸèƒ½å¯ä»¥å°†å„ç§æ ¼å¼çš„æ–‡æ¡£è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®ï¼Œä¾¿äºAIåº”ç”¨ä½¿ç”¨ã€‚

        #### æ”¯æŒçš„æ–‡æ¡£æ ¼å¼
        - **PDFæ–‡ä»¶**ï¼šæ”¯æŒæ–‡æœ¬PDFå’Œæ‰«æPDFï¼ˆä½¿ç”¨OCRï¼‰
        - **Wordæ–‡æ¡£**ï¼šæ”¯æŒ.docxå’Œ.docæ ¼å¼
        - **Excelè¡¨æ ¼**ï¼šæ”¯æŒ.xlsxå’Œ.xlsæ ¼å¼
        - **çº¯æ–‡æœ¬æ–‡ä»¶**ï¼šæ”¯æŒ.txtæ ¼å¼
        - **CSVæ–‡ä»¶**ï¼šæ”¯æŒ.csvæ ¼å¼

        #### è¾“å‡ºæ ¼å¼è¯´æ˜
        - **JSON**ï¼šå®Œæ•´çš„ç»“æ„åŒ–æ•°æ®ï¼ŒåŒ…å«æ–‡æœ¬å—ã€é—®ç­”å¯¹å’Œå…ƒæ•°æ®
        - **JSONL**ï¼šæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¾¿äºæµå¼å¤„ç†
        - **é—®ç­”å¯¹**ï¼šä»æ–‡æ¡£å†…å®¹è‡ªåŠ¨ç”Ÿæˆçš„é—®é¢˜å’Œç­”æ¡ˆå¯¹
        - **æ–‡æœ¬å—**ï¼šåˆ†å‰²åçš„æ–‡æœ¬ç‰‡æ®µï¼Œå¸¦æœ‰å…ƒæ•°æ®

        #### ä½¿ç”¨å»ºè®®
        - å¯¹äºæ‰«æPDFï¼Œè¯·å¯ç”¨OCRé€‰é¡¹
        - æ–‡æœ¬å—å¤§å°å»ºè®®åœ¨300-500ä¹‹é—´ï¼Œä»¥è·å¾—æœ€ä½³çš„è¯­ä¹‰å®Œæ•´æ€§
        - ç”Ÿæˆé—®ç­”å¯¹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§å‹æ–‡æ¡£
        """)

if __name__ == "__main__":
    pass 