#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•è„šæœ¬
ä¸“é—¨æµ‹è¯•å·²ä¿®å¤çš„æ„å›¾è¯†åˆ«å’Œé—®ç­”å¯¹ç”ŸæˆåŠŸèƒ½
"""

import os
import sys
import logging
from pathlib import Path
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

# è®¾ç½®APIå¯†é’¥
os.environ["DEEPSEEK_API_KEY"] = "sk-06810fb5453e4fd1b39e3e5f566da210"

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_intent_recognition_comprehensive():
    """å…¨é¢æµ‹è¯•æ„å›¾è¯†åˆ«åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ§  å…¨é¢æµ‹è¯•æ„å›¾è¯†åˆ«åŠŸèƒ½")
    print("="*60)
    
    try:
        from intent_recognizer import get_intent_recognizer
        
        # åˆå§‹åŒ–æ„å›¾è¯†åˆ«å™¨
        recognizer = get_intent_recognizer(llm_provider="deepseek")
        
        # æ›´å…¨é¢çš„æµ‹è¯•æŸ¥è¯¢
        test_cases = [
            # ä¿¡æ¯æŸ¥è¯¢ç±»
            ("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ", "ä¿¡æ¯æŸ¥è¯¢"),
            ("äººå·¥æ™ºèƒ½çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ", "ä¿¡æ¯æŸ¥è¯¢"),
            ("è¯·ä»‹ç»ä¸€ä¸‹æ·±åº¦å­¦ä¹ ", "ä¿¡æ¯æŸ¥è¯¢"),
            
            # æ¯”è¾ƒç±»é—®é¢˜
            ("æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ", "æ¯”è¾ƒç±»é—®é¢˜"),
            ("Pythonå’ŒJavaå“ªä¸ªæ›´å¥½ï¼Ÿ", "æ¯”è¾ƒç±»é—®é¢˜"),
            ("å¯¹æ¯”ä¸€ä¸‹ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ ", "æ¯”è¾ƒç±»é—®é¢˜"),
            
            # æ·±åº¦è§£é‡Šç±»
            ("è¯¦ç»†è§£é‡Šç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†", "æ·±åº¦è§£é‡Š"),
            ("è¯·æ·±å…¥åˆ†æå·ç§¯ç¥ç»ç½‘ç»œçš„ç»“æ„", "æ·±åº¦è§£é‡Š"),
            ("ä¸ºä»€ä¹ˆè¦ä½¿ç”¨æ¿€æ´»å‡½æ•°ï¼Ÿ", "æ·±åº¦è§£é‡Š"),
            
            # æ¨ç†åˆ†æç±»
            ("ä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ä¸­æ•ˆæœæ›´å¥½ï¼Ÿ", "æ¨ç†åˆ†æ"),
            ("åˆ†æä¸€ä¸‹è¿‡æ‹Ÿåˆäº§ç”Ÿçš„åŸå› ", "æ¨ç†åˆ†æ"),
            ("é¢„æµ‹äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿", "æ¨ç†åˆ†æ"),
            
            # æ“ä½œæŒ‡å—ç±»
            ("å¦‚ä½•è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹ï¼Ÿ", "æ“ä½œæŒ‡å—"),
            ("æ€æ ·è°ƒè¯•æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Ÿ", "æ“ä½œæŒ‡å—"),
            ("å¦‚ä½•é€‰æ‹©åˆé€‚çš„ç®—æ³•ï¼Ÿ", "æ“ä½œæŒ‡å—"),
            
            # ä¸ªäººè§‚ç‚¹ç±»
            ("ä½ è®¤ä¸ºå“ªç§ç®—æ³•æ›´é€‚åˆè¿™ä¸ªåœºæ™¯ï¼Ÿ", "ä¸ªäººè§‚ç‚¹"),
            ("æ¨èä¸€äº›å­¦ä¹ èµ„æº", "ä¸ªäººè§‚ç‚¹"),
            ("ä½ çš„å»ºè®®æ˜¯ä»€ä¹ˆï¼Ÿ", "ä¸ªäººè§‚ç‚¹"),
            
            # é—²èŠç±»
            ("ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ", "é—²èŠ"),
            ("è°¢è°¢ä½ çš„å¸®åŠ©", "é—²èŠ"),
            ("å†è§", "é—²èŠ"),
        ]
        
        correct_predictions = 0
        total_predictions = len(test_cases)
        
        for query, expected_intent in test_cases:
            print(f"\nğŸ“ æµ‹è¯•æŸ¥è¯¢: {query}")
            print(f"   ğŸ¯ æœŸæœ›æ„å›¾: {expected_intent}")
            
            try:
                result = recognizer.recognize_intent(query)
                predicted_intent = result['intent']
                confidence = result['confidence']
                
                print(f"   ğŸ¤– é¢„æµ‹æ„å›¾: {predicted_intent}")
                print(f"   ğŸ“Š ç½®ä¿¡åº¦: {confidence:.3f}")
                
                # æ£€æŸ¥é¢„æµ‹æ˜¯å¦æ­£ç¡®
                if predicted_intent == expected_intent:
                    print(f"   âœ… é¢„æµ‹æ­£ç¡®")
                    correct_predictions += 1
                else:
                    print(f"   âŒ é¢„æµ‹é”™è¯¯")
                
                # æµ‹è¯•æ£€ç´¢ç­–ç•¥
                strategy = recognizer.get_retrieval_strategy(predicted_intent)
                print(f"   ğŸ¯ æ£€ç´¢ç­–ç•¥: top_k={strategy['top_k']}, vector_weight={strategy['vector_weight']}")
                
            except Exception as e:
                print(f"   âŒ é”™è¯¯: {str(e)}")
        
        accuracy = correct_predictions / total_predictions
        print(f"\nğŸ“Š æ„å›¾è¯†åˆ«å‡†ç¡®ç‡: {correct_predictions}/{total_predictions} = {accuracy:.2%}")
        
        # å¦‚æœå‡†ç¡®ç‡è¶…è¿‡70%å°±è®¤ä¸ºæµ‹è¯•é€šè¿‡
        success = accuracy >= 0.7
        if success:
            print("âœ… æ„å›¾è¯†åˆ«æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âŒ æ„å›¾è¯†åˆ«å‡†ç¡®ç‡åä½")
            
        return success
        
    except Exception as e:
        print(f"âŒ æ„å›¾è¯†åˆ«æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_qa_generation_comprehensive():
    """å…¨é¢æµ‹è¯•é—®ç­”å¯¹ç”ŸæˆåŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ’¬ å…¨é¢æµ‹è¯•é—®ç­”å¯¹ç”ŸæˆåŠŸèƒ½")
    print("="*60)
    
    try:
        from data_converter import DocumentConverter
        from langchain.docstore.document import Document
        
        # åˆå§‹åŒ–æ–‡æ¡£è½¬æ¢å™¨
        converter = DocumentConverter(
            llm_provider="deepseek",
            api_key="sk-06810fb5453e4fd1b39e3e5f566da210"
        )
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„æ–‡æœ¬å†…å®¹
        test_contents = [
            # æŠ€æœ¯æ–‡æ¡£
            """
            æœºå™¨å­¦ä¹ ç®—æ³•åˆ†ç±»
            
            ç›‘ç£å­¦ä¹ ï¼š
            ç›‘ç£å­¦ä¹ æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œä½¿ç”¨æ ‡è®°çš„è®­ç»ƒæ•°æ®æ¥å­¦ä¹ è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚
            å¸¸è§ç®—æ³•åŒ…æ‹¬çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœºç­‰ã€‚
            
            æ— ç›‘ç£å­¦ä¹ ï¼š
            æ— ç›‘ç£å­¦ä¹ å¤„ç†æ²¡æœ‰æ ‡ç­¾çš„æ•°æ®ï¼Œç›®æ ‡æ˜¯å‘ç°æ•°æ®ä¸­çš„éšè—æ¨¡å¼ã€‚
            ä¸»è¦åŒ…æ‹¬èšç±»ã€é™ç»´å’Œå…³è”è§„åˆ™å­¦ä¹ ç­‰æ–¹æ³•ã€‚
            """,
            
            # æ¦‚å¿µè§£é‡Š
            """
            æ·±åº¦å­¦ä¹ åŸºç¡€
            
            ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€ï¼Œç”±å¤šä¸ªå±‚æ¬¡çš„ç¥ç»å…ƒç»„æˆã€‚
            æ¯ä¸ªç¥ç»å…ƒæ¥æ”¶è¾“å…¥ï¼Œé€šè¿‡æƒé‡å’Œåç½®è¿›è¡Œè®¡ç®—ï¼Œç„¶åé€šè¿‡æ¿€æ´»å‡½æ•°äº§ç”Ÿè¾“å‡ºã€‚
            åå‘ä¼ æ’­ç®—æ³•ç”¨äºè®­ç»ƒç¥ç»ç½‘ç»œï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™ä¼˜åŒ–æƒé‡å‚æ•°ã€‚
            """,
            
            # åº”ç”¨æ¡ˆä¾‹
            """
            è®¡ç®—æœºè§†è§‰åº”ç”¨
            
            å›¾åƒåˆ†ç±»ï¼šè¯†åˆ«å›¾åƒä¸­çš„ä¸»è¦å¯¹è±¡ç±»åˆ«
            ç›®æ ‡æ£€æµ‹ï¼šå®šä½å¹¶è¯†åˆ«å›¾åƒä¸­çš„å¤šä¸ªå¯¹è±¡
            è¯­ä¹‰åˆ†å‰²ï¼šä¸ºå›¾åƒä¸­çš„æ¯ä¸ªåƒç´ åˆ†é…ç±»åˆ«æ ‡ç­¾
            è¿™äº›æŠ€æœ¯å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ã€å®‰é˜²ç›‘æ§ç­‰é¢†åŸŸã€‚
            """
        ]
        
        total_qa_pairs = 0
        successful_generations = 0
        
        for i, content in enumerate(test_contents):
            print(f"\nğŸ“„ æµ‹è¯•æ–‡æœ¬ {i+1}:")
            print(f"å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            docs = [Document(page_content=content, metadata={"source": f"test_text_{i+1}"})]
            
            # åˆ†å‰²æ–‡æœ¬
            chunks = converter.text_splitter.split_documents(docs)
            print(f"åˆ†å‰²åæ–‡æœ¬å—æ•°é‡: {len(chunks)}")
            
            # ç”Ÿæˆé—®ç­”å¯¹
            start_time = time.time()
            qa_pairs = converter._generate_qa_pairs(chunks)
            gen_time = time.time() - start_time
            
            print(f"ç”Ÿæˆæ—¶é—´: {gen_time:.2f} ç§’")
            print(f"ç”Ÿæˆé—®ç­”å¯¹æ•°é‡: {len(qa_pairs)}")
            
            if len(qa_pairs) > 0:
                successful_generations += 1
                total_qa_pairs += len(qa_pairs)
                
                # æ˜¾ç¤ºç”Ÿæˆçš„é—®ç­”å¯¹
                print("ç”Ÿæˆçš„é—®ç­”å¯¹:")
                for j, qa in enumerate(qa_pairs[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ª
                    print(f"  Q{j+1}: {qa.question}")
                    print(f"  A{j+1}: {qa.answer}")
                    print()
            else:
                print("âŒ æœªç”Ÿæˆä»»ä½•é—®ç­”å¯¹")
        
        print(f"\nğŸ“Š é—®ç­”å¯¹ç”Ÿæˆç»Ÿè®¡:")
        print(f"æˆåŠŸç”Ÿæˆçš„æ–‡æœ¬æ•°: {successful_generations}/{len(test_contents)}")
        print(f"æ€»é—®ç­”å¯¹æ•°é‡: {total_qa_pairs}")
        print(f"å¹³å‡æ¯ä¸ªæ–‡æœ¬ç”Ÿæˆ: {total_qa_pairs/len(test_contents):.1f} ä¸ªé—®ç­”å¯¹")
        
        # å¦‚æœè‡³å°‘æœ‰2/3çš„æ–‡æœ¬æˆåŠŸç”Ÿæˆé—®ç­”å¯¹ï¼Œå°±è®¤ä¸ºæµ‹è¯•é€šè¿‡
        success = successful_generations >= len(test_contents) * 2 / 3
        if success:
            print("âœ… é—®ç­”å¯¹ç”Ÿæˆæµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âŒ é—®ç­”å¯¹ç”ŸæˆæˆåŠŸç‡åä½")
            
        return success
        
    except Exception as e:
        print(f"âŒ é—®ç­”å¯¹ç”Ÿæˆæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_integration():
    """æµ‹è¯•æ„å›¾è¯†åˆ«å’Œé—®ç­”å¯¹ç”Ÿæˆçš„é›†æˆ"""
    print("\n" + "="*60)
    print("ğŸ”— æµ‹è¯•æ„å›¾è¯†åˆ«å’Œé—®ç­”å¯¹ç”Ÿæˆé›†æˆ")
    print("="*60)
    
    try:
        from intent_recognizer import get_intent_recognizer
        from data_converter import DocumentConverter
        from langchain.docstore.document import Document
        
        # åˆå§‹åŒ–ç»„ä»¶
        intent_recognizer = get_intent_recognizer("deepseek")
        converter = DocumentConverter(
            llm_provider="deepseek",
            api_key="sk-06810fb5453e4fd1b39e3e5f566da210"
        )
        
        # æµ‹è¯•åœºæ™¯ï¼šç”¨æˆ·æŸ¥è¯¢ + æ–‡æ¡£å¤„ç†
        user_query = "æ·±åº¦å­¦ä¹ å’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
        document_content = """
        æœºå™¨å­¦ä¹ æŠ€æœ¯å¯¹æ¯”
        
        ä¼ ç»Ÿæœºå™¨å­¦ä¹ ï¼š
        - éœ€è¦æ‰‹å·¥è®¾è®¡ç‰¹å¾
        - æ¨¡å‹ç›¸å¯¹ç®€å•
        - è®­ç»ƒæ•°æ®é‡è¦æ±‚è¾ƒå°
        - å¯è§£é‡Šæ€§è¾ƒå¼º
        
        æ·±åº¦å­¦ä¹ ï¼š
        - è‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤º
        - æ¨¡å‹å¤æ‚ï¼Œå±‚æ¬¡æ·±
        - éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®
        - åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½
        """
        
        print(f"ğŸ¤” ç”¨æˆ·æŸ¥è¯¢: {user_query}")
        
        # 1. æ„å›¾è¯†åˆ«
        intent_result = intent_recognizer.recognize_intent(user_query)
        print(f"ğŸ§  è¯†åˆ«æ„å›¾: {intent_result['intent']} (ç½®ä¿¡åº¦: {intent_result['confidence']:.3f})")
        
        # 2. è·å–é’ˆå¯¹è¯¥æ„å›¾çš„ç­–ç•¥
        strategy = intent_recognizer.get_retrieval_strategy(intent_result['intent'])
        template = intent_recognizer.get_prompt_template(intent_result['intent'])
        print(f"ğŸ¯ æ£€ç´¢ç­–ç•¥: {strategy}")
        print(f"ğŸ“ æç¤ºæ¨¡æ¿: {template[:100]}...")
        
        # 3. å¤„ç†æ–‡æ¡£å¹¶ç”Ÿæˆé—®ç­”å¯¹
        docs = [Document(page_content=document_content, metadata={"source": "comparison_doc"})]
        chunks = converter.text_splitter.split_documents(docs)
        qa_pairs = converter._generate_qa_pairs(chunks)
        
        print(f"ğŸ“„ æ–‡æ¡£å¤„ç†: {len(chunks)} ä¸ªæ–‡æœ¬å—")
        print(f"ğŸ’¬ ç”Ÿæˆé—®ç­”å¯¹: {len(qa_pairs)} ä¸ª")
        
        # 4. æ˜¾ç¤ºç»“æœ
        if qa_pairs:
            print("\nç”Ÿæˆçš„é—®ç­”å¯¹:")
            for i, qa in enumerate(qa_pairs):
                print(f"{i+1}. Q: {qa.question}")
                print(f"   A: {qa.answer}")
                print()
        
        # 5. æ¨¡æ‹ŸåŸºäºæ„å›¾çš„å›ç­”ç”Ÿæˆ
        context = document_content
        prompt = template.format(context=context, question=user_query)
        print(f"ğŸ¤– åŸºäºæ„å›¾çš„æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        success = len(qa_pairs) > 0 and intent_result['confidence'] > 0.5
        if success:
            print("âœ… é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âŒ é›†æˆæµ‹è¯•å¤±è´¥")
            
        return success
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•")
    print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æµ‹è¯•é¡¹ç›®åˆ—è¡¨
    tests = [
        ("æ„å›¾è¯†åˆ«å…¨é¢æµ‹è¯•", test_intent_recognition_comprehensive),
        ("é—®ç­”å¯¹ç”Ÿæˆå…¨é¢æµ‹è¯•", test_qa_generation_comprehensive),
        ("åŠŸèƒ½é›†æˆæµ‹è¯•", test_integration),
    ]
    
    results = []
    start_time = time.time()
    
    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å‡ºç°å¼‚å¸¸: {str(e)}")
            results.append((test_name, False))
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    total_time = time.time() - start_time
    print("\n" + "="*80)
    print("ğŸ“Š æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*80)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:25} : {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡ ({passed/total*100:.1f}%)")
    print(f"æ€»è€—æ—¶: {total_time:.2f} ç§’")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸŒŸ æ„å›¾è¯†åˆ«å’Œé—®ç­”å¯¹ç”ŸæˆåŠŸèƒ½å·²å®Œå…¨ä¿®å¤ï¼")
        print("ğŸš€ ç³»ç»Ÿæ ¸å¿ƒåŠŸèƒ½è¿è¡Œæ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ï¼")
    else:
        print(f"\nâš ï¸  {total-passed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        
    return passed == total

if __name__ == "__main__":
    main() 